[English](../README.md) ¬∑ [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](README.ar.md) ¬∑ [Espa√±ol](README.es.md) ¬∑ [Fran√ßais](README.fr.md) ¬∑ [Êó•Êú¨Ë™û](README.ja.md) ¬∑ [ÌïúÍµ≠Ïñ¥](README.ko.md) ¬∑ [Ti·∫øng Vi·ªát](README.vi.md) ¬∑ [‰∏≠Êñá (ÁÆÄ‰Ωì)](README.zh-Hans.md) ¬∑ [‰∏≠ÊñáÔºàÁπÅÈ´îÔºâ](README.zh-Hant.md) ¬∑ [Deutsch](README.de.md) ¬∑ [–†—É—Å—Å–∫–∏–π](README.ru.md)


[![LazyingArt banner](https://github.com/lachlanchen/lachlanchen/raw/main/figs/banner.png)](https://github.com/lachlanchen/lachlanchen/blob/main/figs/banner.png)

# OpenAIRequestBase Nutzungsanleitung

![Python](https://img.shields.io/badge/Python-3.6%2B-3776AB?logo=python&logoColor=white)
![OpenAI SDK](https://img.shields.io/badge/OpenAI-SDK-111111?logo=openai&logoColor=white)
![Status](https://img.shields.io/badge/Status-Active-2ea44f)
![JSON5](https://img.shields.io/badge/JSON-JSON5-ffb000)
![Cache](https://img.shields.io/badge/Cache-Local%20JSON-0a7ea4)

> Strukturierte OpenAI-Anfragemuster mit JSON-Parsing + Formvalidierung, Retry-Logik und Caching.

---

## ‚ú® Highlights

| Bereich | Details |
|---|---|
| API-Muster | Subclassen Sie und implementieren Sie fokussierte Anfragemethoden rund um eine gemeinsame Retry-Pipeline |
| Ausgabevertrag | Deterministisches JSON-Parsing + Schema-Strukturvalidierung |
| Zuverl√§ssigkeit | Erfolgreiche Antworten cachen, kontextbezogene Wiederholungen und klare Fehlerausgabe |
| Kompatibilit√§t | Python 3.6+, OpenAI SDK, JSON5 |

## üöÄ Schnelle Navigation

| Abschnitt | Link |
|---|---|
| √úberblick | [√úberblick](#overview) |
| Funktionen | [Funktionen](#features) |
| Projektstruktur | [Projektstruktur](#project-structure) |
| Voraussetzungen | [Voraussetzungen](#prerequisites) |
| Installation | [Installation](#installation) |
| Nutzung | [Nutzung](#usage) |
| API-Referenz | [API-Referenz](#api-reference) |
| Konfiguration | [Konfiguration](#configuration) |
| Beispiele | [Beispiele](#examples) |
| Entwicklungshinweise | [Entwicklungshinweise](#development-notes) |
| Fehlerbehebung | [Fehlerbehebung](#troubleshooting) |
| Roadmap | [Roadmap](#roadmap) |
| Mitwirkung | [Mitwirkung](#contribution) |
| Support | [‚ù§Ô∏è Support](#Ô∏è-support) |
| Lizenz | [Lizenz](#license) |

## √úberblick

Dieses Repository stellt `OpenAIRequestBase` bereit, eine wiederverwendbare Basisklasse f√ºr OpenAI-Chat-Completion-Anfragen mit deterministischen, strukturierten JSON-Workflows:

- Eine wiederverwendbare Anfrage-Pipeline aufbauen.
- JSON-√§hnliche Ausgaben robust parsen.
- Die Antwortstruktur gegen eine Vorlage validieren.
- Erfolgreiche Antworten lokal cachen.
- Bei Parsing-/Validierungsfehlern automatisch mit Kontext neu versuchen.

Diese README bewahrt die bestehende Projektdokumentation und erweitert sie zu einer vollst√§ndigen praxisnahen Einrichtungshilfe.

## Funktionen

| Funktion | Beschreibung |
|---|---|
| Kern-API-Wrapper | Die Klasse `OpenAIRequestBase` kapselt die Anfrage-Orchestrierung und Cache-Verwaltung. |
| Retry-Schleife | `send_request_with_retry(...)` wiederholt Aufrufe bei Fehlern bis `max_retries` erreicht ist. |
| JSON-Parsing | `parse_response(...)` extrahiert das erste JSON-Objekt/-Array aus der Modellausgabe und parsed es √ºber `json5`. |
| Formvalidierung | `validate_json(...)` validiert geparstes JSON rekursiv gegen√ºber `sample_json`. |
| Cache-Unterst√ºtzung | Optionaler lokaler Cache mit konfigurierbarem Verzeichnis und optionalem benutzerdefinierten Dateinamen. |
| Modellkonfiguration | Nutzt die Umgebungsvariable `OPENAI_MODEL` oder Fallback `gpt-4-0125-preview`. |
| Fehlerkontext | Retry-Nachrichten h√§ngen Modellausgabe und Ausnahmedetails an die n√§chste Systemnachricht an. |

### Kurz√ºberblick

| Punkt | Wert |
|---|---|
| Hauptimplementierung | `openai_request.py` |
| Kernklasse | `OpenAIRequestBase` |
| Prim√§res Muster | Subklasse + Aufruf von `send_request_with_retry(...)` |
| Standardmodell-Fallback | `gpt-4-0125-preview` |
| Standard-Cache | `cache/<hash(prompt)>.json` |
| i18n-Verzeichnis | `i18n/` (Sprachlinks vorhanden) |

## Projektstruktur

```text
grilling_chatgpt/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ openai_request.py
‚îú‚îÄ‚îÄ i18n/
‚îÇ   ‚îú‚îÄ‚îÄ README.ar.md
‚îÇ   ‚îú‚îÄ‚îÄ README.de.md
‚îÇ   ‚îú‚îÄ‚îÄ README.es.md
‚îÇ   ‚îú‚îÄ‚îÄ README.fr.md
‚îÇ   ‚îú‚îÄ‚îÄ README.ja.md
‚îÇ   ‚îú‚îÄ‚îÄ README.ko.md
‚îÇ   ‚îú‚îÄ‚îÄ README.ru.md
‚îÇ   ‚îú‚îÄ‚îÄ README.vi.md
‚îÇ   ‚îú‚îÄ‚îÄ README.zh-Hans.md
‚îÇ   ‚îî‚îÄ‚îÄ README.zh-Hant.md
‚îî‚îÄ‚îÄ .auto-readme-work/
    ‚îî‚îÄ‚îÄ ...
```

> Annahme: Dieses Repository ist als Bibliothek angelegt (kein CLI), besitzt kein Abh√§ngigkeitsmanifest im Root und hat kein vorab angelegtes `cache/`-Verzeichnis.

## Voraussetzungen

- Python 3.6+
- OpenAI Python-Paket (`openai`)
- JSON5-Parser-Paket (`json5`)
- Zugriff auf OpenAI-Zugangsdaten, nutzbar durch `openai.OpenAI()`

Standardbibliothek-Module, die im Code genutzt werden, sind in den Anforderungen nicht enthalten:

- `os`, `json`, `json5` (extern), `traceback`, `glob`, `re`, `csv`, `datetime`

### Abh√§ngigkeitstabelle

| Paket/Modul | Typ | Erforderlich |
|---|---|---|
| `openai` | Extern | Ja |
| `json5` | Extern | Ja |
| `os`, `json`, `traceback`, `glob`, `re`, `csv`, `datetime` | Standardbibliothek | Nein |

## Installation

Installieren Sie die Abh√§ngigkeiten:

```bash
pip install openai json5
```

Empfohlenes virtuelles Umgebungs-Setup:

```bash
python -m venv .venv
source .venv/bin/activate  # macOS/Linux
pip install --upgrade pip
pip install openai json5
```

## Nutzung

### 1) Basisklasse erweitern

Erstellen Sie eine Unterklasse und exposen Sie eigene Methoden f√ºr dom√§nenspezifische Prompts.

```python
import json
from openai_request import OpenAIRequestBase


class WeatherInfoRequest(OpenAIRequestBase):
    def __init__(self):
        super().__init__(use_cache=True, max_retries=5, cache_dir='weather_cache')

    def get_weather_info(self, location):
        sample_json = {"temperature": "", "condition": ""}
        sample_json_str = json.dumps(sample_json)
        prompt = f"What is the current weather in {location}? Return JSON in the form: {sample_json_str}"
        return self.send_request_with_retry(prompt, sample_json=sample_json)


requester = WeatherInfoRequest()
print(requester.get_weather_info("San Francisco"))
```

### 2) Eine Anfrageinstanz direkt verwenden

```python
from openai_request import OpenAIRequestBase

requester = OpenAIRequestBase(use_cache=True, max_retries=3)
result = requester.send_request_with_retry(
    prompt="Return JSON with fields: {\"ok\": true, \"value\": 42}",
    sample_json={"ok": False, "value": 0},
)
print(result)
```

### 3) Verhalten des Kernaufrufs

`send_request_with_retry(...)`:

1. Liest optional die gecachte Antwort f√ºr den Prompt (oder Dateinamen).
2. Ruft `client.chat.completions.create(...)` auf.
3. Extrahiert JSON-Text und parsed ihn mit `json5`.
4. Validiert gegen `sample_json` (falls angegeben).
5. Speichert die geparste Antwort im Cache.
6. Gibt das geparste JSON zur√ºck, wenn erfolgreich.

Retries h√§ngen die aktuelle Ausgabe und die Ausnahmedetails an die n√§chste Systemnachricht an und wiederholen den Vorgang bis zum Grenzwert.

## API-Referenz

### `OpenAIRequestBase.__init__(use_cache=True, max_retries=3, cache_dir='cache')`
- Richtet den OpenAI-Client ein.
- Steuert die Cache-Strategie.
- Legt das Cache-Verzeichnis √ºber `ensure_dir_exists` vorab an.

### `send_request_with_retry(prompt, system_content='You are an AI.', sample_json=None, filename=None)`
- F√ºhrt die Anfrage-Orchestrierung aus.
- Gibt geparstes JSON zur√ºck.
- Wirft eine generische `Exception`, wenn das Wiederholungslimit erreicht wird.

### `parse_response(response)`
- Findet das erste JSON-Objekt `{...}` oder das erste Array `[...]` und parsed mit `json5`.

### `validate_json(json_data, sample_json)`
- Stellt die Typgleichheit zwischen echten Daten und Muster sicher.
- Pr√ºft erforderliche Dict-Schl√ºssel und validiert Listen-/Elementstruktur rekursiv.

### `get_cache_file_path(prompt, filename=None)`
- Berechnet und pr√ºft den Cache-Pfad.
- Nutzt standardm√§√üig einen deterministischen Hash-Dateinamen: `abs(hash(prompt)).json`.

### `save_to_cache(prompt, response, filename=None)` / `load_from_cache(prompt, filename=None)`
- Schreibt/liest gecachte JSON-Payloads f√ºr deterministische Wiederholbarkeit.

## Konfiguration

### OpenAI-Zugangsdaten

Setzen Sie die Zugangsdaten vor dem Ausf√ºhren. Das tats√§chliche Client-Verhalten wird vom installierten `openai`-Paket verwaltet:

```bash
export OPENAI_API_KEY="your_api_key_here"  # if your environment/client requires this
```

### Modellauswahl

```bash
export OPENAI_MODEL="gpt-4o-mini"  # or any model supported by your account
```

### Cache-Konfiguration

- Schalten Sie mit `use_cache` ein/aus
- Konfigurieren Sie das Cache-Verzeichnis mit `cache_dir`
- √úberschreiben Sie den Dateinamen mit `filename`

```python
requester = OpenAIRequestBase(use_cache=True, cache_dir="my_cache")
result = requester.send_request_with_retry(
    prompt="Return a JSON summary of the weather risk profile.",
    sample_json={"risk_level": "", "notes": []},
    filename="weather/summary.json",
)
```

## Beispiele

### Beispiel A: JSON-Array-Validierung

```python
requester = OpenAIRequestBase()
sample_json = [{"name": "", "age": 0}]
prompt = 'Return a JSON array of people with fields name and age.'
result = requester.send_request_with_retry(prompt=prompt, sample_json=sample_json)
print(result)
```

### Beispiel B: Cache deaktivieren

```python
requester = OpenAIRequestBase(use_cache=False, max_retries=2)
print(requester.send_request_with_retry("Return strict JSON: {\"status\": \"ok\"}", sample_json={"status": ""}))
```

### Beispiel C: Individuellen System-Prompt

```python
requester = OpenAIRequestBase()
result = requester.send_request_with_retry(
    prompt="Return JSON only with keys: summary, sources.",
    system_content="You are a concise JSON-only analyst.",
    sample_json={"summary": "", "sources": []},
)
```

## Entwicklungshinweise

- Dieses Repository enth√§lt weder `requirements.txt`, `pyproject.toml`, `setup.py` noch ein Test-Set im Root.
- Zu den Kern-Imports geh√∂ren mehrere Standardbibliotheksmodule au√üerhalb des Hauptpfads (`csv`, `datetime`, `glob`), die aus Kompatibilit√§tsgr√ºnden erhalten bleiben.
- `parse_response` h√§ngt von Regex-Extraktion ab; wenn die Modellausgabe mehrere JSON-√§hnliche Bl√∂cke enth√§lt, wird ein expliziter Prompt wichtiger.
- JSON-Validierung erzwingt nur Struktur-/Typform, nicht die semantische G√ºltigkeit von Werten.
- Der Retry-Pfad erg√§nzt fr√ºhere KI-Ausgabe und Fehlermeldungsdetails in Folge-Nachrichten, was die Kontextgr√∂√üe erh√∂hen kann.

## Fehlerbehebung

### Symptom: `JSONParsingError` tritt wiederholt auf
- Stellen Sie sicher, dass die Modellausgabe auf reines JSON beschr√§nkt ist.
- Verengen Sie den Prompt und liefern Sie ein explizites Beispiel-Schema.
- Wenn mehrere JSON-Fragmente m√∂glich sind, fordern Sie `Return only one JSON object/array.`

### Symptom: `Maximum retries reached without success`
- Pr√ºfen Sie `OPENAI_API_KEY` und den Netzwerkzugang.
- Best√§tigen Sie, dass der Modellname √ºber `OPENAI_MODEL` f√ºr Ihr Konto existiert.
- Reduzieren Sie die Prompt-Komplexit√§t und pr√ºfen Sie Typ/Form von `sample_json` sorgf√§ltig.

### Symptom: Cache-Hit bleibt aus
- Cache-Dateien werden √ºber den Prompt-Hash adressiert.
- √Ñnderungen am Prompt-Text oder Dateinamen erzeugen einen neuen Cache-Eintrag.
- Pr√ºfen Sie die Berechtigungen des Cache-Verzeichnisses.

### Symptom: Unklare Ausnahmen von `json5`
- F√ºgen Sie im Prompt strikte Beispiele hinzu, besonders f√ºr Strings mit Anf√ºhrungszeichen/Klammern.
- Verwenden Sie zun√§chst einfachere Datenstrukturen (flache Objekte, dann bei Bedarf verschachteln).

## Roadmap

Geplante Verbesserungen im Einklang mit bestehenden Codemustern:

- [ ] F√ºgt eine minimale Test-Suite (`pytest`) f√ºr parse/validate/cache-Verhalten hinzu.
- [ ] F√ºgt strukturierte Protokollierung statt direkter `print`-Ausgaben hinzu.
- [ ] F√ºgt einen optionalen Async-Pfad (`asyncio`-Variante) hinzu.
- [ ] F√ºgt Beispiele f√ºr Batch-Prompts und Multi-Schema-Antworten hinzu.
- [ ] F√ºgt einen optionalen strikten JSON-Schema-Validierungsmodus hinzu.

## Beitrag

Beitr√§ge sind willkommen.

1. Forken Sie das Repository.
2. Erstellen Sie einen Feature-Branch.
3. Aktualisieren Sie README/API-Beispiele und halten Sie Verhaltens√§nderungen an der bestehenden Implementierung ausgerichtet.
4. Testen Sie manuell Request-/Parsing-Pfade (Cache an/aus, Wiederholungen, Validierung).
5. √ñffnen Sie einen PR mit klarer Begr√ºndung und Beispielen.

Empfohlene Beitragsstandards:

- Halten Sie die Dokumentation synchron mit dem Code-Verhalten.
- √Ñndern Sie die Standard-Cache-Struktur nicht, ohne diese README zu aktualisieren.
- Bevorzugen Sie r√ºckw√§rtskompatible √Ñnderungen an der Request-Orchestrierung.

## Lizenz

Es liegt derzeit keine Repository-Lizenzdatei vor. Erg√§nzen Sie eine `LICENSE`-Datei f√ºr rechtliche Klarheit vor einem produktiven Einsatz.


## ‚ù§Ô∏è Support

| Donate | PayPal | Stripe |
| --- | --- | --- |
| [![Donate](https://camo.githubusercontent.com/24a4914f0b42c6f435f9e101621f1e52535b02c225764b2f6cc99416926004b7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d4c617a79696e674172742d3045413545393f7374796c653d666f722d7468652d6261646765266c6f676f3d6b6f2d6669266c6f676f436f6c6f723d7768697465)](https://chat.lazying.art/donate) | [![PayPal](https://camo.githubusercontent.com/d0f57e8b016517a4b06961b24d0ca87d62fdba16e18bbdb6aba28e978dc0ea21/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f50617950616c2d526f6e677a686f754368656e2d3030343537433f7374796c653d666f722d7468652d6261646765266c6f676f3d70617970616c266c6f676f436f6c6f723d7768697465)](https://paypal.me/RongzhouChen) | [![Stripe](https://camo.githubusercontent.com/1152dfe04b6943afe3a8d2953676749603fb9f95e24088c92c97a01a897b4942/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5374726970652d446f6e6174652d3633354246463f7374796c653d666f722d7468652d6261646765266c6f676f3d737472697065266c6f676f436f6c6f723d7768697465)](https://buy.stripe.com/aFadR8gIaflgfQV6T4fw400) |
